{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the following algorithms in Pyspark using any dataset that you are comfortable with (Example – Iris).\n",
    "    1. Decision tree\n",
    "    2. Naïve Bayes classifier\n",
    "    3. Logistic Regression\n",
    "    4. Ensemble models (RandomForest, GBTClassifier)\n",
    "    5. Multilayer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('iris').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/iris.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|speciesIdx|\n",
      "+------------+-----------+------------+-----------+-------+----------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|       0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|       0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|       0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|       0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|       0.0|\n",
      "+------------+-----------+------------+-----------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"speciesIdx\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['sepal_length', 'sepal_width',\n",
    "                                       'petal_length', 'petal_width'],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select('features', 'speciesIdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- speciesIdx: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval = MulticlassClassificationEvaluator(metricName='accuracy', labelCol='speciesIdx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='speciesIdx', featuresCol='features')\n",
    "dtc_model = dtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC Accuracy:  0.96875\n"
     ]
    }
   ],
   "source": [
    "print('DTC Accuracy: ', accuracy_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = NaiveBayes(labelCol='speciesIdx', featuresCol='features')\n",
    "nbc_model = nbc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc_preds = nbc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy:  0.90625\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes Accuracy: ', accuracy_eval.evaluate(nbc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(labelCol='speciesIdx', featuresCol='features')\n",
    "lg_model = log_reg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_preds = lg_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy: ', accuracy_eval.evaluate(lg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ensemble Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc = RandomForestClassifier(labelCol='speciesIdx', featuresCol='features')\n",
    "rtc_model = rtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  0.96875\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Accuracy: ', accuracy_eval.evaluate(rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [4, 5, 4, 3]\n",
    "mlp = MultilayerPerceptronClassifier(labelCol='speciesIdx', featuresCol='features',\n",
    "                                    maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "mlp_model = mlp.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_preds = mlp_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('MLP Accuracy: ', accuracy_eval.evaluate(mlp_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Additional Notes</ins>\n",
    "\n",
    "```\n",
    "- LinearRegression can not be performed on classification problem.\n",
    "\n",
    "- Support vector Machine (LinearSVC), suports only Binary Classification and Iris dataset consists 3 classes.\n",
    "\n",
    "- 2 Ensemble models are natively supported by pyspark, namely:\n",
    "    - GBTClassifier\n",
    "    - RandomForestClassifier\n",
    "\n",
    "- These algorithms do not have inbuilt implementation in pyspark:\n",
    "    - K-nearest Neighbour\n",
    "    - Adaptive Gradient Descent\n",
    "    - Root mean squared Propagation\n",
    "```\n",
    "\n",
    "[reference](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbt = GBTClassifier(labelCol=\"speciesIdx\",\n",
    "#                     featuresCol=\"features\", maxIter=10)\n",
    "# gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# gbtc_preds = gbtc_model.transform(test_data)\n",
    "# print('Gradient-boost Accuracy: ', accuracy_eval.evaluate(gbtc_preds))\n",
    "\n",
    "# ::--> This ends up in an error that I was not able to debug. <--::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defaultvenv",
   "language": "python",
   "name": "defaultvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
